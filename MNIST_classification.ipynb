{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Keras Model - MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits=load_digits()\n",
    "x=digits.data\n",
    "y=digits.target\n",
    "pca=PCA(.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_reduced=pca.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x_reduced,y,test_size=.28,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(29,input_dim=29,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(17,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1293/1293 [==============================] - 3s 2ms/step - loss: 2.8314 - acc: 0.2923\n",
      "Epoch 2/100\n",
      "1293/1293 [==============================] - 1s 439us/step - loss: 1.0043 - acc: 0.6852\n",
      "Epoch 3/100\n",
      "1293/1293 [==============================] - 1s 446us/step - loss: 0.4873 - acc: 0.8685\n",
      "Epoch 4/100\n",
      "1293/1293 [==============================] - 1s 480us/step - loss: 0.2961 - acc: 0.9258\n",
      "Epoch 5/100\n",
      "1293/1293 [==============================] - 1s 433us/step - loss: 0.1994 - acc: 0.9490\n",
      "Epoch 6/100\n",
      "1293/1293 [==============================] - 1s 483us/step - loss: 0.1462 - acc: 0.9652\n",
      "Epoch 7/100\n",
      "1293/1293 [==============================] - 1s 446us/step - loss: 0.1119 - acc: 0.9768\n",
      "Epoch 8/100\n",
      "1293/1293 [==============================] - 1s 452us/step - loss: 0.0880 - acc: 0.9814\n",
      "Epoch 9/100\n",
      "1293/1293 [==============================] - 1s 507us/step - loss: 0.0686 - acc: 0.9884 0s - loss: 0.0504 - \n",
      "Epoch 10/100\n",
      "1293/1293 [==============================] - 1s 470us/step - loss: 0.0550 - acc: 0.9915\n",
      "Epoch 11/100\n",
      "1293/1293 [==============================] - 1s 501us/step - loss: 0.0430 - acc: 0.9946\n",
      "Epoch 12/100\n",
      "1293/1293 [==============================] - 1s 421us/step - loss: 0.0335 - acc: 0.9954\n",
      "Epoch 13/100\n",
      "1293/1293 [==============================] - 1s 405us/step - loss: 0.0273 - acc: 0.9961\n",
      "Epoch 14/100\n",
      "1293/1293 [==============================] - 1s 439us/step - loss: 0.0220 - acc: 0.9985\n",
      "Epoch 15/100\n",
      "1293/1293 [==============================] - 1s 399us/step - loss: 0.0186 - acc: 0.9985\n",
      "Epoch 16/100\n",
      "1293/1293 [==============================] - 1s 430us/step - loss: 0.0155 - acc: 0.9992\n",
      "Epoch 17/100\n",
      "1293/1293 [==============================] - 0s 362us/step - loss: 0.0132 - acc: 0.9992\n",
      "Epoch 18/100\n",
      "1293/1293 [==============================] - 0s 285us/step - loss: 0.0112 - acc: 0.9992\n",
      "Epoch 19/100\n",
      "1293/1293 [==============================] - 0s 282us/step - loss: 0.0096 - acc: 1.0000\n",
      "Epoch 20/100\n",
      "1293/1293 [==============================] - 0s 319us/step - loss: 0.0082 - acc: 1.0000\n",
      "Epoch 21/100\n",
      "1293/1293 [==============================] - 0s 288us/step - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 22/100\n",
      "1293/1293 [==============================] - 0s 285us/step - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "1293/1293 [==============================] - 0s 285us/step - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "1293/1293 [==============================] - 0s 312us/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "1293/1293 [==============================] - 0s 288us/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "1293/1293 [==============================] - 0s 275us/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "1293/1293 [==============================] - 0s 322us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "1293/1293 [==============================] - 0s 282us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "1293/1293 [==============================] - 0s 278us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "1293/1293 [==============================] - ETA: 0s - loss: 0.0023 - acc: 1.000 - 0s 303us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "1293/1293 [==============================] - 0s 288us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "1293/1293 [==============================] - 0s 240us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "1293/1293 [==============================] - 0s 239us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "1293/1293 [==============================] - 0s 251us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "1293/1293 [==============================] - 0s 260us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "1293/1293 [==============================] - 0s 241us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "1293/1293 [==============================] - 0s 238us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "1293/1293 [==============================] - 0s 263us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "1293/1293 [==============================] - 0s 269us/step - loss: 9.2627e-04 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "1293/1293 [==============================] - 0s 231us/step - loss: 8.4186e-04 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "1293/1293 [==============================] - 0s 235us/step - loss: 7.6828e-04 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "1293/1293 [==============================] - 0s 248us/step - loss: 7.0101e-04 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "1293/1293 [==============================] - 0s 263us/step - loss: 6.4169e-04 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "1293/1293 [==============================] - 0s 257us/step - loss: 5.8557e-04 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "1293/1293 [==============================] - 0s 241us/step - loss: 5.3809e-04 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "1293/1293 [==============================] - 0s 247us/step - loss: 4.9159e-04 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "1293/1293 [==============================] - 0s 248us/step - loss: 4.5325e-04 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "1293/1293 [==============================] - 0s 236us/step - loss: 4.1417e-04 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "1293/1293 [==============================] - 0s 235us/step - loss: 3.8066e-04 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "1293/1293 [==============================] - 0s 257us/step - loss: 3.5412e-04 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "1293/1293 [==============================] - 0s 257us/step - loss: 3.2584e-04 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "1293/1293 [==============================] - 0s 235us/step - loss: 2.9677e-04 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "1293/1293 [==============================] - 0s 244us/step - loss: 2.7398e-04 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "1293/1293 [==============================] - 0s 260us/step - loss: 2.4888e-04 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "1293/1293 [==============================] - 0s 248us/step - loss: 2.2942e-04 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "1293/1293 [==============================] - 0s 251us/step - loss: 2.1159e-04 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "1293/1293 [==============================] - 0s 232us/step - loss: 1.9500e-04 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "1293/1293 [==============================] - 0s 269us/step - loss: 1.8132e-04 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "1293/1293 [==============================] - 0s 244us/step - loss: 1.6752e-04 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "1293/1293 [==============================] - 0s 235us/step - loss: 1.5490e-04 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "1293/1293 [==============================] - 0s 277us/step - loss: 1.4106e-04 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "1293/1293 [==============================] - 0s 235us/step - loss: 1.3118e-04 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "1293/1293 [==============================] - 0s 186us/step - loss: 1.2135e-04 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "1293/1293 [==============================] - 0s 195us/step - loss: 1.1228e-04 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "1293/1293 [==============================] - 0s 183us/step - loss: 1.0351e-04 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "1293/1293 [==============================] - 0s 192us/step - loss: 9.5830e-05 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "1293/1293 [==============================] - 0s 204us/step - loss: 8.8792e-05 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "1293/1293 [==============================] - 0s 189us/step - loss: 8.1828e-05 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "1293/1293 [==============================] - 0s 192us/step - loss: 7.5489e-05 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "1293/1293 [==============================] - 0s 189us/step - loss: 7.0107e-05 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "1293/1293 [==============================] - 0s 217us/step - loss: 6.5086e-05 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "1293/1293 [==============================] - 0s 192us/step - loss: 6.0222e-05 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "1293/1293 [==============================] - 0s 170us/step - loss: 5.5725e-05 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "1293/1293 [==============================] - 0s 179us/step - loss: 5.1980e-05 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "1293/1293 [==============================] - 0s 189us/step - loss: 4.8083e-05 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "1293/1293 [==============================] - 0s 198us/step - loss: 4.4784e-05 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "1293/1293 [==============================] - 0s 152us/step - loss: 4.1555e-05 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "1293/1293 [==============================] - 0s 161us/step - loss: 3.8780e-05 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "1293/1293 [==============================] - 0s 161us/step - loss: 3.5707e-05 - acc: 1.0000\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1293/1293 [==============================] - 0s 149us/step - loss: 3.3259e-05 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "1293/1293 [==============================] - 0s 145us/step - loss: 3.0872e-05 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "1293/1293 [==============================] - 0s 164us/step - loss: 2.8729e-05 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "1293/1293 [==============================] - 0s 142us/step - loss: 2.6706e-05 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "1293/1293 [==============================] - 0s 183us/step - loss: 2.4757e-05 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "1293/1293 [==============================] - 0s 229us/step - loss: 2.3015e-05 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "1293/1293 [==============================] - 0s 242us/step - loss: 2.1415e-05 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "1293/1293 [==============================] - 0s 244us/step - loss: 1.9934e-05 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "1293/1293 [==============================] - 0s 221us/step - loss: 1.8557e-05 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "1293/1293 [==============================] - 0s 244us/step - loss: 1.7259e-05 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "1293/1293 [==============================] - 0s 238us/step - loss: 1.6114e-05 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "1293/1293 [==============================] - 0s 254us/step - loss: 1.5080e-05 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "1293/1293 [==============================] - 0s 223us/step - loss: 1.4014e-05 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "1293/1293 [==============================] - 0s 226us/step - loss: 1.3075e-05 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "1293/1293 [==============================] - 0s 235us/step - loss: 1.2129e-05 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "1293/1293 [==============================] - 0s 255us/step - loss: 1.1360e-05 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "1293/1293 [==============================] - 0s 311us/step - loss: 1.0557e-05 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "1293/1293 [==============================] - 1s 427us/step - loss: 9.8537e-06 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "1293/1293 [==============================] - 1s 483us/step - loss: 9.2471e-06 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "1293/1293 [==============================] - 1s 421us/step - loss: 8.6340e-06 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "1293/1293 [==============================] - 1s 483us/step - loss: 8.0580e-06 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xc55c9f128>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=5, batch_size=10,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504/504 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "scores=model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=[]\n",
    "for i in range(len(a)):\n",
    "    for j in range(len(a[0])):\n",
    "        if max(a[i])==a[i][j]:\n",
    "            predicted.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_=np.array(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=accuracy_score(predicted_,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9682539682539683"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
