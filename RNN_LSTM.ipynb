{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN TRAINS THROUGH BACKPROPAGATION AND IT HAPPENS FOR EACH TIME STAMP\n",
    "# KNOWN AS BACKPROPAGATION THROUGH TIME\n",
    "# VANISHING AND EXPLODING GRADIENT\n",
    "# THE CHANGE IN WEIGHT WILL BECOME LESSER AFTER MULTIPLE TIME STAMP(MULTIPLYING WITH LEARNING RATE)\n",
    "# TO STOP EXPLODING GRADIENT - TRUNCATED BPN THROUGH TIME (BTT) (DOES NOT GO TILL THE STARTING,STARTS FROM SOMEWHERE INBETWEEN)\n",
    "#                            - CLIP GRADIENT AFTER A CERTAIN THRESHOLD\n",
    "#                            - RMS PROP TO ADJUST LEARNING RATE\n",
    "# FOR VANISHING - ReLu\n",
    "#               - RMSprop\n",
    "#               - LSTM , GRU\n",
    "# LSTMS- LONG SHORT TIME MEMORY NETWORKS - LEARNS LONG TIME DEPEDENCIES\n",
    "# LSTMS HAVE FOUR INTERACTING LAYERS\n",
    "# CELL STATE - LINEAR INTERACTION\n",
    "# 1) SIGMOID LAYER (FORGET GATE LAYER) - DECIDES WHAT INFORMATION TO THROW AWAY FROM THE CELL STATE\n",
    "#               - INPUTS VALUE FROM PREVIOUS TIME STAMP (H(t-1)) AND INPUT (x(t)) AND OUTPUTS A NUMBER BETWEEN 0 AND 1\n",
    "#                  FOR EACH NUMBER IN THE CELL STATE\n",
    "#               - f(t)=sigmoid(Wf*[H(t-1),X(t)]+B)\n",
    "# 2) DECIDE WHAT INFORMATION TO STORE\n",
    "#                HAS 2 PARTS :- i) SIGMOID LAYER TO DECIDE WHAT ALL TO UPDATE\n",
    "#                              ii) CREATES A VECTOR OF THE CANDIDATE VALUES THAT WILL BE ADDED TO THE STATE LATER ON\n",
    "#                BOTH VALUES FROM PREVIOUS STATE AND INPUT IS PASSED THROUGH THESE TWO LAYERS\n",
    "#                BOTH PASS THROUGH SIGMOID TO GIVE I(t) AND BOTH PASS THROUGH tanh TO GIVE `Ç(t)\n",
    "#                I(t) AND C(t) ARE MULTIPLIED AND ADDED TO CELL STATE\n",
    "#                I(t)=sigmoid(Wi*[H(t-1),X(t)]+Bi)       `Ç(t)=tanh(Wc*[H(t-1),X(t)]+Bc)\n",
    "#\n",
    "# 3) OLD STATE C(t-1) IS UPDATED TO C(t)\n",
    "#    C(t) = f(t)*C(t-1) + I(t)*`Ç(t)\n",
    "#    1st TERM IS USED FOR FORGETTING THE TERMS THAT ARE NOT REQUIRED\n",
    "#    2nd TERM GIVES US THE SCALED VALUE AS TO HOW MUCH WE DECIDE TO UPDATE EACH VALUE\n",
    "# 4) DECIDING WHAT TO OUTPUT BASED ON OUR CELL STATE \n",
    "#    O(t)=sigmoid(Wo*[H(t-1),X(t)]+Bo)\n",
    "#    h(t)= O(t)*tanh(C(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "target=[]\n",
    "temp=[]\n",
    "for i in range(100):\n",
    "    for j in range(8):\n",
    "        temp.append(i+j)\n",
    "    data.append(temp)\n",
    "    temp=[]\n",
    "    target.append(i+5)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "data_scaled=scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled=np.array(data_scaled)\n",
    "data_scaled=data_scaled.reshape([100,8,1])\n",
    "target=np.array(target)\n",
    "target=target.reshape([100,1])\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder=OneHotEncoder(categories='auto')\n",
    "target_encoded=encoder.fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encoded=target_encoded.toarray().reshape([100,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(target_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(data_scaled,target_encoded,random_state=42,test_size=.28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ( output size)\n",
    "#(batch_input_shape-input shape of data) format (no of input,length of input sequence,length of each vector)\n",
    "# if not known , can be replaced with None\n",
    "# return sequence - 'True' gives output at each node | 'False' does not give output at each node\n",
    "model.add(LSTM(1,batch_input_shape=(None,8,1),return_sequences=True))\n",
    "model.add(LSTM(1,return_sequences=True))\n",
    "model.add(LSTM(1,return_sequences=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(100,activation='tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(100,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.3253 - acc: 0.9577\n",
      "Epoch 2/10\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.3424 - acc: 0.9437\n",
      "Epoch 3/10\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.3471 - acc: 0.9296\n",
      "Epoch 4/10\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.3022 - acc: 0.9718\n",
      "Epoch 5/10\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.3088 - acc: 0.9718\n",
      "Epoch 6/10\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2954 - acc: 0.9718\n",
      "Epoch 7/10\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2987 - acc: 0.9718\n",
      "Epoch 8/10\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.3019 - acc: 0.9577\n",
      "Epoch 9/10\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.2921 - acc: 0.9859\n",
      "Epoch 10/10\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.3027 - acc: 0.9859\n"
     ]
    }
   ],
   "source": [
    "results=model.fit(x_train,y_train,epochs=10,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "for i in range(len(y_predicted)):\n",
    "    for j in range(len(y_predicted[0])):\n",
    "        if max(y_predicted[i])==y_predicted[i][j]:\n",
    "            l.append(1)\n",
    "        else :\n",
    "            l.append(0)\n",
    "l=np.array(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE LENGTH OF INPUT SHOULD BE FLEXIBLE\n",
    "# i) USE PADDING ii) USE (NONE,NONE,1) IN PLACE OF batch_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=l.reshape([29,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 87],\n",
       "       [ 59],\n",
       "       [ 76],\n",
       "       [ 51],\n",
       "       [ 48],\n",
       "       [ 43],\n",
       "       [ 28],\n",
       "       [ 86],\n",
       "       [ 16],\n",
       "       [  6],\n",
       "       [ 24],\n",
       "       [ 34],\n",
       "       [ 79],\n",
       "       [ 39],\n",
       "       [ 94],\n",
       "       [ 10],\n",
       "       [ 80],\n",
       "       [ 83],\n",
       "       [ 16],\n",
       "       [ 37],\n",
       "       [ 61],\n",
       "       [ 94],\n",
       "       [ 32],\n",
       "       [ 48],\n",
       "       [ 73],\n",
       "       [ 21],\n",
       "       [ 46],\n",
       "       [100],\n",
       "       [ 13]])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.inverse_transform(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 88],\n",
       "       [ 58],\n",
       "       [ 75],\n",
       "       [ 50],\n",
       "       [ 49],\n",
       "       [ 44],\n",
       "       [ 27],\n",
       "       [ 85],\n",
       "       [ 15],\n",
       "       [  5],\n",
       "       [ 23],\n",
       "       [ 35],\n",
       "       [ 78],\n",
       "       [ 38],\n",
       "       [ 95],\n",
       "       [  9],\n",
       "       [ 81],\n",
       "       [ 82],\n",
       "       [ 17],\n",
       "       [ 36],\n",
       "       [ 60],\n",
       "       [ 93],\n",
       "       [ 31],\n",
       "       [ 47],\n",
       "       [ 74],\n",
       "       [ 20],\n",
       "       [ 45],\n",
       "       [101],\n",
       "       [ 14]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "29/29 [==============================] - 0s 552us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[16.11809539794922, 0.0]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
